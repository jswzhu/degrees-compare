





ExploreOnline DegreesDegreesOnline DegreeExplore Bachelorâs & Masterâs degreesMasterTrackâ¢Earn credit towards a Masterâs degreeUniversity CertificatesAdvance your career with graduate-level learningFind your New CareerFor EnterpriseFor UniversitiesBrowseTop CoursesLog InJoin for FreeListInference for comparing two independent meansLoading...Inferential StatisticsDuke UniversityFilled StarFilled StarFilled StarFilled StarFilled Star4.8 (2,525 ratings)Â |Â 110K Students EnrolledCourse 2 of 3 in the Data Analysis with R SpecializationEnroll for FreeThis CourseVideo TranscriptThis course covers commonly used statistical inference methods for numerical and categorical data. You will learn how to set up and perform hypothesis tests, interpret p-values, and report the results of your analysis in a way that is interpretable for clients or the public. Using numerous data examples, you will learn to report estimates of quantities in a way that expresses the uncertainty of the quantity of interest. You will be guided through installing and using R and RStudio (free statistical software), and will use this software for lab exercises and a final project. The course introduces practical tools for performing data analysis and explores the fundamental concepts necessary to interpret and report results for both categorical and numerical dataView SyllabusSkills You'll LearnStatistical Inference, Statistical Hypothesis Testing, R ProgrammingReviewsFilled StarFilled StarFilled StarFilled StarFilled Star4.8 (2,525 ratings)5 stars83.12%4 stars13.30%3 stars1.94%2 stars0.63%1 star0.99%DSMar 7, 2017Filled StarFilled StarFilled StarFilled StarFilled StarThis course is an excellent overview of inferential statistic tests / hypothesis tests and confidence intervals. The organization and material is quite good, with exercises and applications using R.Helpful?RRJun 14, 2017Filled StarFilled StarFilled StarFilled StarFilled StarAwesome. I loved the way this course is done. I know what Test Statistic to use for what type of data and under which conditions. I am preparing a cheat-sheet that will be shared with all later on.Helpful?From the lessonInference for Comparing MeansWelcome to Week Three of the course! This week we will introduce the t-distribution and comparing means as well as a simulation based method for creating a confidence interval: bootstrapping. If you have questions or discussions, please use this week's forum to ask/discuss with peers.Introduction4:04t-distribution7:20Inference for a mean9:44Inference for comparing two independent means8:56Inference for comparing two paired means9:02Power11:03Taught ByMine Ãetinkaya-RundelAssociate Professor of the PracticeTry the Course for FreeTranscriptSelect a languageArabicEnglishFrenchGermanItalianKoreanRussianSpanishVietnameseptPtIn this video, we return to the distracted eaters study and compare the average snack  consumption of distracted and non-distracted eaters post-lunch.  As a reminder,  the study was called Playing a Computer Game During Lunch Affects Fullness,  Memory for Lunch, and Later Snack Intake.  The researchers set out to the evaluate the relationship between distraction, and  recall of food consumed, and snacking.  They had a sample of 44 volunteer patients, 22 of them men and  22 of them women, that they randomized into two equally-sized groups.  One group played solitaire on the computer while eating, and  was instructed to win as many games as possible.  In other words, they were asked to focus on the game.  The other group was asked to eat their lunch without any distractions,  focusing on what they were eating.  Both groups were provided the same amount of lunch and  offered the same amount of biscuits to snack on afterwards.  The researchers measured the snack consumption of subjects in each group.  The study reports average snack consumption levels for  both groups, as well as the standard deviations.  Suppose we want to estimate how much more, or less,  distracted eaters snack compared to non-distracted eaters.  We would use a confidence interval for  this, which is always of the form, point estimate plus or minus a margin of error.  The point estimate is the difference between the two sample averages, and  the margin of error can be calculated as a critical value  times the standard error of the difference between the two sample means.  So the only new concept here is this new standard error,  which can be calculated as the square root of the sum of the variances for  each group, divided by their respective sample sizes.  Note that we add the two variances even though we're looking for  the standard error of the difference of the two means.  This is not simple to prove mathematically with only the tools we've  learned in this course so far, but conceptually, you can think about it as  bringing together two measures with an inherent variability around them.  These are two sample means.  When you bring two unknowns together, the result should always be more variable,  regardless of whether you're adding them or subtracting them.  And the degrees of freedom for the t statistic, for comparing two independent  means can be calculated as the minimum of the sample sizes of the two samples,  minus 1.  You might come across a few other estimates for the degrees of freedom for  comparing two means, perhaps in another textbook or so, but what we noted here is  actually not the exact degrees of freedom, which is quite tedious to compute by hand.  The estimate of degrees of freedom we noted here, is a conservative estimate,  since it relies on the lower of the two sample sizes.  As with all inferential methods, there are some conditions that we need to meet.  First is independence, both within and between the groups.  We can verify the within group independence  assumption via random sampling or  assignment, and the 10% condition, if you're sampling without replacement.  Note that the 10% condition in this case means that both N1 and  N2 should be less than 10% of their respective populations.  If both of these are met, then we can assume that the observations in our study  are independent of each other with respect to the variable,  the outcome variable that we're studying.  We also want the two groups to be independent of each other.  Failure to meet this condition is not inherently a problem though, but  it just means that we would need to use methods suited for  dependent, or in other words, paired groups.  We will introduce these methods in another lesson.  And the second condition is about the sample size and skew.  The more skewed the population distributions,  the larger the samples we need from those populations.  Let's estimate the difference between the average post-meal snack consumption  between those who eat with and without distractions.  The confidence interval will be of the form point estimate, that is  the difference between the two sample means, plus or minus a margin of error.  That is a critical T-score times the standard error of the difference between  the two sample means.  This is (52.1- 27.1) plus or minus 2.08  x the square root of 45.1 squared over 22 + 26.4 squared over 22,  which yields a standard error estimate of 11.14,  and a margin of error of 23.17 grams,  the confidence interval is then 1.83 to 48.17 grams.  Next, we'll work on a hypothesis test for evaluating whether these data provide  convincing evidence of a difference between their average post-meal  snack consumption between those who eat with and without distractions.  When doing a hypothesis test, the first step is always to set your hypotheses.  Remember that the null hypothesis always says there's  absolutely nothing going on here.  We could phrase that as the average snack consumption for those who eat with and  without distraction, the difference between those two is 0.  Another way of thinking about this is that the two mus  from the two populations are equal to each other.  Note that I'm using mus and not x-bars because the hypotheses  are always about the populations and never about the samples.  We already know the sample statistics, we don't need to hypothesize about them.  We want to use those sample statistics to say something about  the unknown population parameters.  The alternative hypothesis is then that there is a difference between the two  population means, or that the difference is not 0.  We calculate ofurtest statistic, which is a T-score with 21 degrees of freedom,  as the observed difference, the 25 we saw earlier, minus the null value of 0,  divided by the standard error we calculated earlier of 11.14.  This yields a T statistic of 2.24.  The last step before making a decision on these hypotheses is to find the p-value,  but before we can do that we must sketch the sampling distribution.  We do that and shade the tail areas corresponding to our p-value.  Let's recap everything we've done so far.  We started with a study where the researchers randomly assigned respondents  into distracted and non-distracted eating groups and  compared their snack intake post-meal.  The sample statistic suggested that the distracted eaters  consumed more snacks on average.  However, just because we observe a difference in the sample means,  doesn't necessarily mean that there is something going on  that is statistically significant in the actual populations.  So, we use statistical inference tools to evaluate if this apparent  relationship between distracted eating and  snacking more provide evidence of a real difference at the population level.  Note that we have a randomized control trial here, so  if we do indeed find a significant result,  we could then talk about a causal relationship between these two variables.  The confidence interval for  the average difference was 1.83 to 48.17 and the hypothesis test  evaluating a different between the two means yielded a p-value of roughly 4%.  Which means that we would reject the null hypothesis and conclude that  these data do indeed provide convincing evidence that there is a difference  between the average snack intake of distracted and non-distracted eaters.  And do the results of the confidence interval and the hypothesis test agree?  We used similar methods, so they really should.  We rejected the null hypothesis that set  the difference between the two means equal to 0, and therefore this  null value should not be included in our confidence interval and indeed it's not.  Therefore, the results from the hypothesis test and the confidence interval do agree.Explore our CatalogJoin for free and get personalized recommendations, updates and offers.Get Started

Coursera FooterStart or advance your careerGoogle Data AnalystGoogle Digital Marketing & E-commerce Professional CertificateGoogle IT Automation with Python Professional CertificateGoogle IT SupportGoogle Project ManagementGoogle UX DesignPreparing for Google Cloud Certification: Cloud ArchitectIBM Cybersecurity AnalystIBM Data AnalystIBM Data EngineeringIBM Data ScienceIBM Full Stack Cloud DeveloperIBM Machine LearningIntuit BookkeepingMeta Front-End DeveloperDeepLearning.AI TensorFlow Developer Professional CertificateSAS Programmer Professional CertificateLaunch your careerPrepare for a certificationAdvance your careerHow to Identify Python Syntax ErrorsHow to Catch Python ExceptionsSee all Programming TutorialsPopular Courses and CertificationsFree CoursesArtificial Intelligence CoursesBlockchain CoursesComputer Science CoursesCursos GratisCybersecurity CoursesData Analysis CoursesData Science CoursesEnglish Speaking CoursesFull Stack Web Development CoursesGoogle CoursesHuman Resources CoursesIT CoursesLearning English CoursesMicrosoft Excel CoursesProduct Management CoursesProject Management CoursesPython CoursesSQL CoursesAgile CertificationsCAPM CertificationCompTIA A+ CertificationData Analytics CertificationsScrum Master CertificationsSee all coursesPopular collections and articlesFree online courses you can finish in a dayPopular Free CoursesBusiness JobsCybersecurity JobsEntry-Level IT JobsData Analyst Interview QuestionsData Analytics ProjectsHow to Become a Data AnalystHow to Become a Project ManagerIT SkillsProject Manager Interview QuestionsPython Programming SkillsStrength and Weakness in InterviewWhat Does a Data Analyst DoWhat Does a Software Engineer DoWhat Is a Data EngineerWhat Is a Data ScientistWhat Is a Product DesignerWhat Is a Scrum MasterWhat Is a UX ResearcherHow to Get a PMP CertificationPMI CertificationsPopular Cybersecurity CertificationsPopular SQL CertificationsRead all Coursera ArticlesEarn a degree or certificate onlineGoogle Professional CertificatesProfessional CertificatesSee all certificatesBachelor's DegreesMaster's DegreesComputer Science DegreesData Science DegreesMBA & Business DegreesData Analytics DegreesPublic Health DegreesSocial Sciences DegreesManagement DegreesBA vs BS DegreeWhat is a Bachelor's Degree?11 Good Study Habits to DevelopHow to Write a Letter of Recommendation10 In-Demand Jobs You Can Get with a Business DegreeIs a Master's in Computer Science Worth it?See all degree programsCoursera IndiaCoursera UKCoursera MexicoCourseraAboutWhat We OfferLeadershipCareersCatalogCoursera PlusProfessional CertificatesMasterTrackÂ® CertificatesDegreesFor EnterpriseFor GovernmentFor CampusBecome a PartnerCoronavirus ResponseCommunityLearnersPartnersBeta TestersTranslatorsBlogTech BlogTeaching CenterMorePressInvestorsTermsPrivacyHelpAccessibilityContactArticlesDirectoryAffiliatesModern Slavery StatementLearn AnywhereÂ© 2023 Coursera Inc. All rights reserved.